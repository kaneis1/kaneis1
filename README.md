# Hi, I'm **Kaniel Cui** 👋

AI/ML practitioner focused on **decision-making**, **offline RL**, and **sequence modeling**.  
Based in **Atlanta, USA**.  

[![LinkedIn](https://img.shields.io/badge/LinkedIn-zongqi--cui-blue)](https://www.linkedin.com/in/zongqi-cui-532648208/)
[![ORCID](https://img.shields.io/badge/ORCID-0009--0002--3890--9167-brightgreen)](https://orcid.org/0009-0002-3890-9167)

---

## What I’m working on

- **Diplomacy + Transformers** — building a pipeline to train sequence models (e.g., Decision Transformer) on **no-press Diplomacy** trajectories and evaluate via self-play/bot benchmarks.
- **Human decision modeling** — reproducing and extending RNN/Transformer baselines on classic behavioral tasks (IPD, IGT), with better evaluation and tooling.

---

## Highlights (repos)

- 🔁 **[Decision-transformer](https://github.com/kaneis1/Decision-transformer)** — experiments with DT and dataset tooling (includes a `decision-transformer/` training skeleton and `choices13k/` data prep).  
- ♟️ **[diplomacy](https://github.com/kaneis1/diplomacy)** (fork) — environment & network code compatible with the **No-Press Diplomacy** setting; includes action/observation encodings and tests to validate agents.  
- 🧠 **[HumanLSTM](https://github.com/kaneis1/HumanLSTM)** (fork) — codebase for predicting human decisions in psychological tasks (IPD, IGT) with LSTM/BERT-style models; multiple versions and figures.

> Pinned projects above reflect my current focus areas in offline RL + behavior modeling.

---

## Interests & tools

- **Interests:** Offline RL, sequence modeling (Transformers), game AI, behavioral data, evaluation & reproducibility.  
- **Tools:** Python, PyTorch, NumPy, Pandas, scikit-learn; experiment tracking, data pipelines, and evaluation scripts.

---

## Connect

- 💼 **LinkedIn:** [zongqi-cui-532648208](https://www.linkedin.com/in/zongqi-cui-532648208/)  
- 🧪 **ORCID:** [0009-0002-3890-9167](https://orcid.org/0009-0002-3890-9167)

---


