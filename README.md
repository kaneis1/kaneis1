# Hi, I'm **Kaniel Cui** ðŸ‘‹

AI/ML practitioner focused on **decision-making**, **offline RL**, and **sequence modeling**.  
Based in **Atlanta, USA**.  

[![LinkedIn](https://img.shields.io/badge/LinkedIn-zongqi--cui-blue)](https://www.linkedin.com/in/zongqi-cui-532648208/)
[![ORCID](https://img.shields.io/badge/ORCID-0009--0002--3890--9167-brightgreen)](https://orcid.org/0009-0002-3890-9167)

---

## What Iâ€™m working on

- **Diplomacy + Transformers** â€” building a pipeline to train sequence models (e.g., Decision Transformer) on **no-press Diplomacy** trajectories and evaluate via self-play/bot benchmarks.
- **Human decision modeling** â€” reproducing and extending RNN/Transformer baselines on classic behavioral tasks (IPD, IGT), with better evaluation and tooling.

---

## Highlights (repos)

- ðŸ” **[Decision-transformer](https://github.com/kaneis1/Decision-transformer)** â€” experiments with DT and dataset tooling (includes a `decision-transformer/` training skeleton and `choices13k/` data prep).  
- â™Ÿï¸ **[diplomacy](https://github.com/kaneis1/diplomacy)** (fork) â€” environment & network code compatible with the **No-Press Diplomacy** setting; includes action/observation encodings and tests to validate agents.  
- ðŸ§  **[HumanLSTM](https://github.com/kaneis1/HumanLSTM)** (fork) â€” codebase for predicting human decisions in psychological tasks (IPD, IGT) with LSTM/BERT-style models; multiple versions and figures.

> Pinned projects above reflect my current focus areas in offline RL + behavior modeling.

---

## Interests & tools

- **Interests:** Offline RL, sequence modeling (Transformers), game AI, behavioral data, evaluation & reproducibility.  
- **Tools:** Python, PyTorch, NumPy, Pandas, scikit-learn; experiment tracking, data pipelines, and evaluation scripts.

---

## Connect

- ðŸ’¼ **LinkedIn:** [zongqi-cui-532648208](https://www.linkedin.com/in/zongqi-cui-532648208/)  
- ðŸ§ª **ORCID:** [0009-0002-3890-9167](https://orcid.org/0009-0002-3890-9167)

---


